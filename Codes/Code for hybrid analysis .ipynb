{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8YDYLrqAE_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4db2c7-1fa5-4f9d-ccb3-d176bd414ead"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        " \n",
        "# define cnn model\n",
        "def define_vggmodel():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "# define model\n",
        "  model = define_vggmodel()\n",
        "\t# create data generator\n",
        "  datagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "  datagen.mean = [123.68, 116.779, 103.939]\n",
        "  #for validation set\n",
        "  datagen_valid = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "  datagen_valid.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "  train_it = datagen.flow_from_directory('/content/drive/MyDrive/train/',   #path for training images\n",
        "\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "  valid_it = datagen_valid.flow_from_directory('/content/drive/MyDrive/valid/',   #path for valid images\n",
        "\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "  # fit model\n",
        "  #steps_per_epoch=len(train_it)\n",
        "  model.fit_generator(train_it,validation_data = valid_it,steps_per_epoch=20 , epochs=10, verbose=0)#changed above here so as to compile :p\n",
        "\t# save model\n",
        "  model.save('/content/drive/MyDrive/final_vggmodel.h5')    #saving model \n",
        "\n",
        "# Make predictions\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6205 images belonging to 2 classes.\n",
            "Found 2067 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHwIn2EBzOVd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072bba64-267b-4e04-c7e7-3f3345283e1b"
      },
      "source": [
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "def define_iv3model():\n",
        "\t# load model\n",
        "\tmodel = InceptionV3(include_top=False, input_shape=(299, 299, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_inception():\n",
        "# define model\n",
        "  model = define_iv3model()\n",
        "\t# create data generator\n",
        "  datagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "  datagen.mean = [123.68, 116.779, 103.939]\n",
        "  # create data generator\n",
        "  datagen_valid = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "  datagen_valid.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "  train_it = datagen.flow_from_directory('/content/drive/MyDrive/train/',\n",
        "    class_mode='binary', batch_size=64, target_size=(299, 299))\n",
        "  valid_it = datagen_valid.flow_from_directory('/content/drive/MyDrive/valid/',\n",
        "    class_mode='binary', batch_size=64, target_size=(299, 299))\n",
        "  \n",
        "\t# fit model\n",
        "  #steps_per_epoch=len(train_it),\n",
        "  model.fit_generator(train_it,validation_data = valid_it, steps_per_epoch=20, epochs=10, verbose=0)\n",
        "\t# save model\n",
        "  model.save('/content/drive/MyDrive/final_iv3model.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_inception()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6205 images belonging to 2 classes.\n",
            "Found 2067 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgajiF8LYCG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cecf00-78dc-4709-ce19-aa9d6a734aff"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "def define_rn50model():\n",
        "\t# load model\n",
        "\tmodel = ResNet50(include_top=False, input_shape=(224, 224, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_resnet50():\n",
        "# define model\n",
        "\tmodel = define_rn50model()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
        "  # create data generator\n",
        "\tdatagen_valid = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen_valid.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('/content/drive/MyDrive/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(224, 224))\n",
        " \t# prepare iterator\n",
        "\tvalid_it = datagen_valid.flow_from_directory('/content/drive/MyDrive/valid/',\n",
        "    class_mode='binary', batch_size=64, target_size=(224, 224))\n",
        "\n",
        "\t# fit model\n",
        "  #steps_per_epoch=len(train_it)\n",
        "\tmodel.fit_generator(train_it,validation_data = valid_it, steps_per_epoch=20, epochs=10, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('/content/drive/MyDrive/final_rn50model.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_resnet50()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6205 images belonging to 2 classes.\n",
            "Found 2067 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ujc4N7NrMNP1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951e0eee-a5d0-4ce8-d3c0-62451c995643"
      },
      "source": [
        "from tensorflow.keras.applications import Xception\n",
        "\n",
        "def define_xceptionmodel():\n",
        "\t# load model\n",
        "\tmodel = Xception(include_top=False, input_shape=(299, 299, 3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        " \n",
        "# run the test harness for evaluating a model\n",
        "def run_xception():\n",
        "# define model\n",
        "\tmodel = define_xceptionmodel()\n",
        "\t# create data generator\n",
        "\tdatagen = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen.mean = [123.68, 116.779, 103.939]\n",
        "  \t# create data generator\n",
        "\tdatagen_valid = ImageDataGenerator(featurewise_center=True)\n",
        "\t# specify imagenet mean values for centering\n",
        "\tdatagen_valid.mean = [123.68, 116.779, 103.939]\n",
        "\t# prepare iterator\n",
        "\ttrain_it = datagen.flow_from_directory('/content/drive/MyDrive/train/',\n",
        "\t\tclass_mode='binary', batch_size=64, target_size=(299, 299))\n",
        " \t# prepare iterator\n",
        "\tvalid_it = datagen_valid.flow_from_directory('/content/drive/MyDrive/valid/',\n",
        "    class_mode='binary', batch_size=64, target_size=(299, 299))\n",
        "\n",
        "\t# fit model\n",
        "  #steps_per_epoch=len(train_it)\n",
        "\tmodel.fit_generator(train_it,validation_data = valid_it, steps_per_epoch=20, epochs=10, verbose=0)\n",
        "\t# save model\n",
        "\tmodel.save('/content/drive/MyDrive/final_xceptionmodel.h5')\n",
        " \n",
        "# entry point, run the test harness\n",
        "run_xception()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6205 images belonging to 2 classes.\n",
            "Found 2067 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdPB-KKYAvya"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "def convert_to_img(path): \n",
        "  f = open(path, mode='r',encoding='utf-8')\n",
        "  image = np.fromfile(f, dtype=np.ubyte)\n",
        "  filesize = image.shape[0]\n",
        "  width = 224   #width set at 224 for resnet 50 and vgg16\n",
        "  rem = filesize%width\n",
        "  if rem != 0:\n",
        "    image = image[:-rem]\n",
        "  height = int(image.shape[0]/width)      #height based on file size\n",
        "  image = image.reshape(height,width)\n",
        "  #im = Image.fromarray(image)\n",
        "  return image"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHSDrYvoRV2r"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "  # load and prepare the image\n",
        "def load_image2(path,flag_of_img=False):    #for incpetion and xception as both have same input format \n",
        "# load the image\n",
        "  if (flag_of_img==False):\n",
        "    image=convert_to_img(path)\n",
        "    new_image = np.copy(image)\n",
        "    new_image = np.resize(new_image, (299,299,3))\n",
        "    new_image= np.expand_dims(new_image, axis= 0) \n",
        "    img = new_image.reshape(1,299,299,3)\n",
        "  if (flag_of_img):\n",
        "    filename = path\n",
        "    image=load_img(filename,target_size=(299,299))\n",
        "  # convert to array\n",
        "    img=img_to_array(image)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "    img = img.reshape(1, 299, 299, 3)\n",
        "  # center pixel data\n",
        "  img = img.astype('float32')\n",
        "  img = img - [123.68, 116.779, 103.939]\n",
        "  return img\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbvRgvaqAPHA",
        "outputId": "1ae52824-14da-47b2-d321-74ea54b82adb"
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "\n",
        "  # load and prepare the image\n",
        "def load_image1(path,flag_of_img=False):    #for vgg and resnet50 as both have same input format \n",
        "# load the image\n",
        "  if (flag_of_img==False):\n",
        "    image=convert_to_img(path)\n",
        "    new_image = np.copy(image)\n",
        "    new_image = np.resize(new_image, (224,224,3))\n",
        "    new_image= np.expand_dims(new_image, axis= 0) \n",
        "    img = new_image.reshape(1,224,224,3)\n",
        "  if (flag_of_img):\n",
        "    filename = path\n",
        "    image=load_img(filename,target_size=(224,224))\n",
        "  # convert to array\n",
        "    img=img_to_array(image)\n",
        "\t# reshape into a single sample with 3 channels\n",
        "    img = img.reshape(1, 224, 224, 3)\n",
        "  # center pixel data\n",
        "  img = img.astype('float32')\n",
        "  img = img - [123.68, 116.779, 103.939]\n",
        "  return img\n",
        " \n",
        "# load an image and predict the class\n",
        "def run_example1():\n",
        "  model3 = load_model('/content/drive/MyDrive/all models/final_iv3model.h5')\n",
        "  model4 = load_model('/content/drive/MyDrive/all models/final_xceptionmodel.h5')\n",
        "  model2 = load_model('/content/drive/MyDrive/all models/final_rn50model.h5')\n",
        "  # load the image\n",
        "  img1 = load_image1('/content/Copy_of_Workbook_2.ipynb',False)\n",
        "  img2 = load_image2('/content/Copy_of_Workbook_2.ipynb',False)\n",
        "  # load model\n",
        "  model1 = load_model('/content/drive/MyDrive/all models/final_vggmodel.h5')\n",
        "  # predict the class\n",
        "  result1 = model1.predict(img1)\n",
        "  print(\"VGG16 \")\n",
        "  print(result1[0])\n",
        "  result2= model2.predict(img1)\n",
        "  print(\"resnet50 \")\n",
        "  print(result2[0])\n",
        "  result3 = model3.predict(img2)\n",
        "  print(\"incpetionV3 \")\n",
        "  print(result3[0])\n",
        "  result4 = model4.predict(img2)\n",
        "  print(\"xception \")\n",
        "  print(result4[0])\n",
        "  r1= result1[0]\n",
        "  count = 0\n",
        "  if(r1>0.80):\n",
        "    count = count + 1\n",
        "    print(\"malicious file!!!!\")\n",
        "  r2= result2[0]\n",
        "  if(r2>0.80):\n",
        "    count = count + 1\n",
        "    print(\"malicious file!!!!\")\n",
        "  r3= result3[0]\n",
        "  if(r3>0.80):\n",
        "    count = count + 1\n",
        "    print(\"malicious file!!!!\")\n",
        "  r4= result4[0]\n",
        "  if(r4>0.80):\n",
        "    count = count + 1\n",
        "    print(\"malicious file!!!!\")\n",
        "\n",
        "  if count>2:\n",
        "    print('malicious')\n",
        "run_example1()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fecce4d15f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "VGG16 \n",
            "[0.9998349]\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fedb3018320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "resnet50 \n",
            "[0.95592564]\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fedb3db4b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "incpetionV3 \n",
            "[0.49392217]\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fedba23d170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "xception \n",
            "[0.43853554]\n",
            "malicious file!!!!\n",
            "malicious file!!!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}