#Lets Create the Features from json files

import json
import pandas as pd
import csv
import os
import sys
import codecs #open and write multiple 

# Load the Drive helper and mount
from google.colab import drive

# This will prompt for authorization.
#drive.mount('/content/drive/My Drive/Colab Notebooks/FYPTestingFolder/FinalFolder/DataSet/') (due to spaces this method does not work)
#print("Loaded 1st box")

#tokanized paramters/features
token_feat = [ "behavior.processes.modules.basename","signatures.marks.call.api","signatures.marks.ioc","network.domains.domain"]
#print("loaded 2nd box")

#features per report
def feat_extract(json_var, feat_Array_key):
    #non-empty values
    if feat_Array_key:
        indiviual_keyIndex = 0
        indiviual_key = feat_Array_key[0]

        if type( json_var ) is dict:
            print("Haan bhai scene hai")
            #no values loaded in dictionary
            if not json_var:
                print( "Empty json dictionary being sent, correct the path" )
                return
            print("Current json variables", json_var )
            if indiviual_key in json_var.keys():
                print("key value hai")
                json_var =  json_var[indiviual_key]
            else:
                print( "Koi value nahin hai" )
                return

            print("json_var", str(json_var) )
            print("feature arrays", feat_Array_key[indiviual_keyIndex+1:] )
            if not ( ( type( json_var ) is dict ) or ( type( json_var ) is list ) ) and bool(json_var):
                    feat_extract_array.append(json_var)
            else: 
                feat_extract( json_var, feat_Array_key[indiviual_keyIndex+1:] )

        #For a list
        elif type( json_var ) is list:
            # return from function if list is empty
            if not json_var:

                print( "Json list -> dictionary empty" )
                return
            for index, value in enumerate( json_var ):
                print( "List values yeh hain afaq, yeh wali save horahi hain: ",value )
                if not value:
                    print( "No nested list -.-" )
                    continue
                feat_extract( value, feat_Array_key[indiviual_keyIndex:] )
            print("save ho gayi list")
            # check if feature accessor has only one value left
            if not json_var:
                    print("Empty json, go back")
                    return
            feat_extract( json_var, feat_Array_key[indiviual_keyIndex+1:] )
        else:
            print(json_var)
            #print("Should be a single value")

#print("loaded 3rd box")

#Dataframe and lists for saving features
feature_frame = pd.DataFrame()
datapath = "/content/"
#datapath = "/contents/benign_report.json"

#print("loaded 4th box")

for filename in os.listdir(datapath):
    # Only parse json files
    if filename.endswith('.json'): 
        exclusive_feature = []
        exclusive_feature.clear()
        feat_extract_array = []
        feat_extract_array.clear()
        #empty lists ready to fill
        # open file in read mode
        with open( os.path.join( datapath, filename ), "r" ) as indiviual_report:
            # load the json variable
            indiviual_report_json =  json.load( indiviual_report )
            # test the file for presence of predefined nested features
            for indiviual_required_feature in  token_feat:
                nested_feature = indiviual_required_feature.split(".")
                feat_extract( indiviual_report_json, nested_feature )
                feature_frame.at[filename, "class"] = 1   #(uncomment this or next line other depending on the dataset being prepared)
                #feature_frame.at[filename, "class"] = 0
                for item in feat_extract_array:
                    temp_feature = indiviual_required_feature + "." + item
                    exclusive_feature.append( temp_feature )
                    feature_frame.at[ filename, temp_feature] = 1
            print("Exclusive Feature: ", exclusive_feature)

            print( feature_frame.head() )
            with codecs.open("/content/feature_frame1.csv", 'wb', encoding='utf-8', errors='ignore') as f:
              feature_frame.to_csv( f )

#print("loaded 5th box")
